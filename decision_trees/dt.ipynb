{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = None \n",
    "\n",
    "def get_np_array(file_name):\n",
    "    global label_encoder\n",
    "    data = pd.read_csv(file_name)\n",
    "    \n",
    "    need_label_encoding = ['team','host','opp','month', 'day_match']\n",
    "    if(label_encoder is None):\n",
    "        label_encoder = OrdinalEncoder()\n",
    "        label_encoder.fit(data[need_label_encoding])\n",
    "    data_1 = pd.DataFrame(label_encoder.transform(data[need_label_encoding]), columns = label_encoder.get_feature_names_out())\n",
    "    \n",
    "    #merge the two dataframes\n",
    "    dont_need_label_encoding =  [\"year\",\"toss\",\"bat_first\",\"format\" ,\"fow\",\"score\" ,\"rpo\" ,\"result\"]\n",
    "    data_2 = data[dont_need_label_encoding]\n",
    "    final_data = pd.concat([data_1, data_2], axis=1)\n",
    "    \n",
    "    X = final_data.iloc[:,:-1]\n",
    "    y = final_data.iloc[:,-1:]\n",
    "    v1 = X.to_numpy()\n",
    "    v2 = y.to_numpy()\n",
    "    return (v1,v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = get_np_array(\"../data/train.csv\") \n",
    "X_test, Y_test = get_np_array(\"../data/test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTNode:\n",
    "\n",
    "    def __init__(self, depth, features, labels, is_leaf = False, value = 0, column = None):\n",
    "\n",
    "        #to split on column\n",
    "        self.depth = depth\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        #add children afterwards\n",
    "        self.children = None\n",
    "\n",
    "        #if leaf then also need value\n",
    "        self.is_leaf = is_leaf\n",
    "        if(self.is_leaf):\n",
    "            self.value = value\n",
    "        \n",
    "        if(not self.is_leaf):\n",
    "            self.column = column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTTree:\n",
    "\n",
    "    def __init__(self):\n",
    "        #Tree root should be DTNode\n",
    "        self.root = None       \n",
    "\n",
    "    def fit(self, X, y, types, max_depth = 10):\n",
    "        self.x = X \n",
    "        self.y = y \n",
    "        self.type = types\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "\n",
    "    def find_entropy(self, features, labels): # finds H[labels] \n",
    "        counts = np.unique(labels, return_counts=True)[1] \n",
    "        print(counts) \n",
    "        counts = counts / (labels.shape[0]) \n",
    "        entropy = -1 * np.sum(counts * math.log2(counts))  \n",
    "        return entropy \n",
    "\n",
    "    def find_conditional_entropy(self, features, labels, attribute): # finds H[labels | attribute] \n",
    "        entropy = 0 \n",
    "        total_size = features.shape[0]\n",
    "        if (self.type[attribute] == \"cat\"):\n",
    "            \n",
    "            \n",
    "            no_of_attribute_vals = np.unique(features[:, attribute]).shape[0] \n",
    "            for i in range(no_of_attribute_vals):\n",
    "                new_features = features[features[:, attribute] == i] \n",
    "                new_labels = labels[features[:, attribute] == i]\n",
    "                size = new_features.shape[0] \n",
    "                entropy += (size/total_size) * self.find_entropy(new_features, new_labels) \n",
    "        \n",
    "        else:\n",
    "            attribute_vals = features[:, attribute] \n",
    "            sorted_feature = np.sort(attribute_vals) \n",
    "            median_val = sorted_feature[(sorted_feature.shape[0] - 1) //2] \n",
    "            feature_1 = features[features[:, attribute] <= median_val] \n",
    "            feature_2 = features[features[:, attribute] > median_val]\n",
    "            labels_1 = labels[features[:, attribute] <= median_val]\n",
    "            labels_2 = labels[features[:, attribute] > median_val]\n",
    "\n",
    "            entropy += (feature_1.shape[0]/total_size) * self.find_entropy(feature_1, labels_1)\n",
    "            entropy += (feature_2.shape[0]/total_size) * self.find_entropy(feature_2, labels_2)\n",
    "\n",
    "        \n",
    "        return entropy \n",
    "\n",
    "    def find_split_attribute(self):\n",
    "        max_gain = -1 \n",
    "        split_attribute = None \n",
    "        init_entropy = self.find_entropy(self.features, self.labels)\n",
    "        for attribute in range(self.features.shape[1]):\n",
    "            gain = init_entropy - self.find_conditional_entropy(self.features, self.labels, attribute) \n",
    "            if gain > max_gain:\n",
    "                max_gain = gain \n",
    "                split_attribute = attribute \n",
    "        \n",
    "        return split_attribute\n",
    "    \n",
    "    def grow_tree(self, features, labels, depth): # returns a DTNode \n",
    "        node = DTNode(depth, features, labels)  \n",
    "        # set is_leaf, value, column \n",
    "        if (depth == self.max_depth):\n",
    "            # terminate \n",
    "            node.is_leaf = True \n",
    "        \n",
    "            return \n",
    "        y_count = np.unique(labels).shape[0] \n",
    "        if (y_count == 1):\n",
    "            # terminate \n",
    "            return \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def __call__(self, X):\n",
    "        '''\n",
    "        Predicted classes for X\n",
    "        Args:\n",
    "            X: numpy array of data [num_samples, num_features]\n",
    "        Returns:\n",
    "            y: [num_samples, 1] predicted classes\n",
    "        '''\n",
    "        #TODO\n",
    "    \n",
    "    def post_prune(self, X_val, y_val):\n",
    "        return\n",
    "        #TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
